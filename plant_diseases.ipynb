{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD05WHgvEZv-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "gpu_devices = tf.config.list_physical_devices('GPU')\n",
        "if gpu_devices:\n",
        "    print(f\"✅ GPU Detected: {gpu_devices}\")\n",
        "    BATCH_SIZE = 64\n",
        "else:\n",
        "    print(\"⚠️ No GPU detected. Go to Runtime > Change runtime type > T4 GPU\")\n",
        "    BATCH_SIZE = 32\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/practice/archive.zip'\n",
        "extract_path = '/content/plant_data_extracted'\n",
        "\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    print(\"Unzipping dataset... (This will take ~3-5 mins due to 2.7GB size)\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"Unzipping Complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted. Skipping unzip.\")\n",
        "\n",
        "\n",
        "base_inner = os.path.join(extract_path, 'New Plant Diseases Dataset(Augmented)', 'New Plant Diseases Dataset(Augmented)')\n",
        "train_dir = os.path.join(base_inner, 'train')\n",
        "valid_dir = os.path.join(base_inner, 'valid')\n",
        "\n",
        "\n",
        "test_dir_raw = os.path.join(extract_path, 'test', 'test')\n",
        "\n",
        "\n",
        "print(f\"Train Folder Found: {os.path.exists(train_dir)}\")\n",
        "print(f\"Test Images Found: {len(os.listdir(test_dir_raw)) if os.path.exists(test_dir_raw) else 0}\")\n",
        "\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "print(\"\\n--- Loading Data ---\")\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "\n",
        "base_model = MobileNetV2(input_shape=IMG_SIZE + (3,), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.2)(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(f\"\\nStarting Training with Batch Size {BATCH_SIZE}...\")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=5,\n",
        "    validation_data=valid_generator\n",
        ")\n",
        "\n",
        "\n",
        "print(\"\\n--- Testing on Unseen Images ---\")\n",
        "class_map = {v: k for k, v in train_generator.class_indices.items()}\n",
        "\n",
        "\n",
        "test_files = os.listdir(test_dir_raw)\n",
        "import random\n",
        "selected_files = random.sample(test_files, min(len(test_files), 5))\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for i, file in enumerate(selected_files):\n",
        "    path = os.path.join(test_dir_raw, file)\n",
        "\n",
        "\n",
        "    img = load_img(path, target_size=IMG_SIZE)\n",
        "    img_arr = img_to_array(img)\n",
        "    img_arr = np.expand_dims(img_arr, axis=0) / 255.0\n",
        "\n",
        "\n",
        "    pred = model.predict(img_arr, verbose=0)\n",
        "    pred_class_index = np.argmax(pred)\n",
        "    pred_label = class_map[pred_class_index]\n",
        "    confidence = np.max(pred)\n",
        "\n",
        "\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"{pred_label}\\n({confidence*100:.1f}%)\", fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xX5eOCgoE9TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/plant_data_extracted/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'\n",
        "\n",
        "class_names = sorted(os.listdir(train_dir))\n",
        "\n",
        "\n",
        "joblib.dump(class_names, '/content/drive/MyDrive/Plant_Project/plant_disease_classes.pkl')\n",
        "\n",
        "print(f\"Success! Saved {len(class_names)} disease classes to Google Drive.\")\n",
        "print(\"Here are the first few classes just to be sure:\", class_names[:3])"
      ],
      "metadata": {
        "id": "zaIRgrojzP5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Plant_Project/plant_disease_model.h5')"
      ],
      "metadata": {
        "id": "Gn1ciObmFYDI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}